{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salles97/Project_Data_View/blob/main/PCO114_Explorando_Dados_com_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://raw.githubusercontent.com/flavio-mota/fundamentos-pln/master/unifei-inpe.png\" align=\"right\" width=\"150\" />\n",
        "\n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "# <span style=\"color:#336699\">Visualização de Informação - Perfil de Dados com Python</span>\n",
        "<hr style=\"border:2px solid #0077b9;\">\n",
        "\n",
        "<br/>\n",
        "\n",
        "<div style=\"text-align: center;font-size: 90%;\">\n",
        "    Autores:<br/>\n",
        "    Flávio Belizário da Silva Mota¹<br/>\n",
        "    Melise Maria Veiga de Paula²\n",
        "    <br/><br/>\n",
        "    ¹Instituto Nacional de Pesquisas Espaciais (INPE) <br/>\n",
        "    ²Universidade Federal de Itajubá (UNIFEI)\n",
        "    <br/>\n",
        "    <br/>\n",
        "    Contato: <a href=\"mailto:flavio.mota@inpe.com\">flavio.mota@inpe.com</a>\n",
        "    <br/>\n",
        "    04/10/2023\n",
        "    <br>\n",
        "</div>\n",
        "\n",
        "<br/>\n",
        "\n",
        "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;\">\n",
        "<b>Objetivo.</b> Esse caderno Jupyter tem como objetivo apresentar um <i>template</i> para a implementação de uma estratégia para coletar, descrever, explorar e verificar a qualidade de um conjunto de dados.\n",
        "</div>"
      ],
      "metadata": {
        "id": "lBkrvQYSogyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando a biblioteca necessária\n",
        "<hr style=\"border:2px solid #0077b9;\">"
      ],
      "metadata": {
        "id": "HaJrcZaK5EcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para apresentar o exemplo dessa aula, precisaremos instalar uma das bibliotecas do ambiente colab que usaremos para gerar as descrições dos nossos dados. Isso é necessário porque o Colab é uma máquina virtual que é instanciada com algumas bibliotecas padrão para análise de dados e aprendizado de máquina. Entretanto, por se tratarem de bibliotecas do python, elas podem não estar instaladas ou ficarem desatualizadas e perder o suporte da versão da linguagem. Podemos instalar a biblioteca <code>ydata-profiling</code> utilizando o comando abaixo:\n",
        "\n"
      ],
      "metadata": {
        "id": "cvRq4nTL5MXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ydata-profiling"
      ],
      "metadata": {
        "id": "g9cTh-L82QEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3526237c-5dea-470d-e2a2-17765b48dd4b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ydata-profiling\n",
            "  Downloading ydata_profiling-4.6.0-py2.py3-none-any.whl (357 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/357.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m357.5/357.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<1.12,>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.11.3)\n",
            "Requirement already satisfied: pandas!=1.4.0,<2.1,>1.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.5.3)\n",
            "Requirement already satisfied: matplotlib<=3.7.3,>=3.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.7.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.10.13)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (6.0.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (3.1.2)\n",
            "Collecting visions[type_image_path]==0.7.5 (from ydata-profiling)\n",
            "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/102.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.26,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.23.5)\n",
            "Collecting htmlmin==0.1.12 (from ydata-profiling)\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting phik<0.13,>=0.11.1 (from ydata-profiling)\n",
            "  Downloading phik-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (679 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m679.5/679.5 kB\u001b[0m \u001b[31m57.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (2.31.0)\n",
            "Requirement already satisfied: tqdm<5,>=4.48.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (4.66.1)\n",
            "Requirement already satisfied: seaborn<0.13,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.12.2)\n",
            "Collecting multimethod<2,>=1.4 (from ydata-profiling)\n",
            "  Downloading multimethod-1.10-py3-none-any.whl (9.9 kB)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.14.0)\n",
            "Collecting typeguard<5,>=4.1.2 (from ydata-profiling)\n",
            "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
            "Collecting imagehash==4.3.1 (from ydata-profiling)\n",
            "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.5/296.5 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wordcloud>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (1.9.2)\n",
            "Collecting dacite>=1.8 (from ydata-profiling)\n",
            "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba<0.59.0,>=0.56.0 in /usr/local/lib/python3.10/dist-packages (from ydata-profiling) (0.56.4)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (1.4.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from imagehash==4.3.1->ydata-profiling) (9.4.0)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (23.1.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.10/dist-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (3.1)\n",
            "Collecting tangled-up-in-unicode>=0.0.4 (from visions[type_image_path]==0.7.5->ydata-profiling)\n",
            "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m91.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<=3.7.3,>=3.2->ydata-profiling) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba<0.59.0,>=0.56.0->ydata-profiling) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba<0.59.0,>=0.56.0->ydata-profiling) (67.7.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas!=1.4.0,<2.1,>1.1->ydata-profiling) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1.8.1->ydata-profiling) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.24.0->ydata-profiling) (2023.7.22)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.3)\n",
            "Collecting typing-extensions>=4.2.0 (from pydantic<2,>=1.8.1->ydata-profiling)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n",
            "Building wheels for collected packages: htmlmin\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27081 sha256=3c8e00fe9537f26401664de756f34cf70416d59abac8e61e04cde68bc95ff07d\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/91/29/a79cecb328d01739e64017b6fb9a1ab9d8cb1853098ec5966d\n",
            "Successfully built htmlmin\n",
            "Installing collected packages: htmlmin, typing-extensions, tangled-up-in-unicode, multimethod, dacite, typeguard, imagehash, visions, phik, ydata-profiling\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dacite-1.8.1 htmlmin-0.1.12 imagehash-4.3.1 multimethod-1.10 phik-0.12.3 tangled-up-in-unicode-0.2.0 typeguard-4.1.5 typing-extensions-4.8.0 visions-0.7.5 ydata-profiling-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coletando os dados\n",
        "<hr style=\"border:2px solid #0077b9;\">"
      ],
      "metadata": {
        "id": "ICp-bsHc3PK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como exemplo de coleta de dados, vamos trabalhar com o conjunto de dados fornecido e, nesse caso, carregar a base a partir de um arquivo CSV. Para isso utilizaremos a biblioteca <code>pandas</code>.<br/><br/>\n",
        "De forma muito resumida, essa biblioteca é uma das mais empregadas (se não a mais) para análise de dados com Python. Ela permite trabalhar com dados estruturados ou tabulares de forma rápida e fácil. A principal estrutura da biblioteca é o <code>DataFrame</code>, que é uma estrutura de dados tabular, orientada a colunas, com rótulos tanto para as linhas quanto para colunas. Existem também as <code>Series</code>, que são objetos de array unidimensional com rótulo. Veremos essas estruturas na prática posteriormente.<br/><br/>\n",
        "Mais detalhes da biblioteca podem ser encontrados em <a>https://pandas.pydata.org/</a>."
      ],
      "metadata": {
        "id": "AjYb0LQ13ajO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos importar a biblioteca <code>pandas</code> e <code>ydata-profiling</code>, definir a <i>URL</i> da qual vamos coletar o conjunto de dados e por fim ler o arquivo CSV em uma estrutura <code>DataFrame</code>:"
      ],
      "metadata": {
        "id": "hioNtVLvAje4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xep4CI4Yr23V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # importando pandas\n",
        "from ydata_profiling import ProfileReport # importando ydata_profiling\n",
        "\n",
        "# Define a url com o arquivo CSV que será utilizado\n",
        "url = 'https://raw.githubusercontent.com/flavio-mota/PCO114_2022/main/dados/datatran2020.csv'\n",
        "\n",
        "# Lê o arquivo CSV com a biblioteca pandas e salva em uma estrutura DataFrame na variável df\n",
        "# Atenção para o parâmetro 'sep'. É ele que define o caracter separador do arquivo CSV\n",
        "df = pd.read_csv(url, sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que temos nossos dados carregados em um <code>DataFrame</code>, podemos começar a explorá-lo utilizando todos os recursos da biblioteca."
      ],
      "metadata": {
        "id": "HGvYBUJzBfxV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descrevendo os dados\n",
        "<hr style=\"border:2px solid #0077b9;\">"
      ],
      "metadata": {
        "id": "_U5m9yGDCTX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após coletar os dados e armazená-los em uma estrutura <code>DataFrame</code>, podemos acessar alguns atributos dessa estrutura que são capazes de trazer algumas informações sobre os dados. A primeira informação que podemos consultar é sobre o tamanho do conjunto de dados. Podemos fazer isso com o comando a seguir:"
      ],
      "metadata": {
        "id": "HrC1j042DA87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ZYfoxPMbzmGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3a8d86-3737-4aa4-9ab2-9c31a7f1cc30"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15708, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado exibido informa a quantidade de linhas e colunas do nosso conjunto de dados. Vamos deixar essa informação mais agradável para o nosso relatório:"
      ],
      "metadata": {
        "id": "NNGz9Z_kFN13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('O conjunto contém %s registros (linhas) e %s colunas (atributos).' % (df.shape[0], df.shape[1]))"
      ],
      "metadata": {
        "id": "J42HttSjzqFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ce548d-1ec3-469b-8f43-592992b2d75d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O conjunto contém 15708 registros (linhas) e 30 colunas (atributos).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos verificar quais são as colunas/atributos do conjunto com o seguinte comando:"
      ],
      "metadata": {
        "id": "dM8b0DPsFoDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "wX2YjNyKz9yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que sabemos o que nome de cada coluna, podemos verificar os tipos de dados que cada uma delas armazena e também se existem valores ausentes:"
      ],
      "metadata": {
        "id": "QSY_1kH1NH7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "CasZjGt1NVVz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "O resultado retornado nos mostra que temos colunas que armazenam dados do tipo inteiro (<code>int64</code>), numérico/ponto flutuante (<code>float64</code>) e dados do tipo <code>object</code>. O tipo <code>object</code> pela documentação da biblioteca pandas, representa um tipo de \"objeto arbitrário\". As cadeias de caracteres também são entendidas pela biblioteca como sendo desse tipo. Nem todas as colunas possuem dados, uma vez que a coluna <code>Non-Null Count</code> apresentou o valores diferentes para cada coluna."
      ],
      "metadata": {
        "id": "ERywV3zCNsH0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos visualizar alguns registros do conjunto de dados para ter uma noção do que cada um deles armazena:"
      ],
      "metadata": {
        "id": "8KRudXj6PxOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "mAPYSeKU0EgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No comando acima, listamos os 5 primeiros registros do conjunto de dados e algumas de suas colunas. Por serem muitas colunas, o pandas oculta algumas delas para não sobrecarregar a visualização. Aqui já conseguimos ter uma pequena noção de como são nossos dados e que valores eles apresentam. Podemos solicitar ao <code>DataFrame</code> uma descrição do conjunto de dados através do comando abaixo:"
      ],
      "metadata": {
        "id": "fUelRlWMQFew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# O parâmetro include com o valor \"all\" é informado aqui porque temos variáveis categóricas (object) no conjunto\n",
        "# e sem esse parâmetro, o método describe retornaria descrições somente dos dados numéricos\n",
        "df.describe(include='all')"
      ],
      "metadata": {
        "id": "_RkgYKmY0M-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Através do método <code>describe()</code> é possível extrair algumas medidas estatísticas do conjunto, como contagens, valores únicos, valores mais frequentes, média, desvio padrão, valor mínimo e máximo e as distribuições por quartis."
      ],
      "metadata": {
        "id": "gBM52k3PRCac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uma outra forma mais prática e agradável de descrever e explorar os dados que facilita muito essa etapa é utilizar a biblioteca <code>pandas-profiling</code>. Essa biblioteca gera relatórios a partir de um <code>DataFrame</code>. A função <code>describe()</code> é útil, mas um pouco básica para análise exploratória de dados. Para cada coluna, um conjunto de informações (sempre que relevantes para o tipo de coluna) são apresentadas em um relatório HTML interativo. Para isso, vamos utilizar o comando a seguir:"
      ],
      "metadata": {
        "id": "kJPnRYgfSIw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profile = ProfileReport(df, title='Descrevendo os dados', html={'style':{'full_width':True}})"
      ],
      "metadata": {
        "id": "t-Y2XsJI0w86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esse comando define qual a fonte de dados que queremos usar para gerar o relatório, o título que queremos dar a ele e alguns parâmetros de estilo para o HTML que será gerado. Para construir de fato o relatório, usamos o comando a seguir. O processo pode ser demorado a depender do conjunto de dados."
      ],
      "metadata": {
        "id": "vSDjsyH2TG7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profile.to_notebook_iframe()"
      ],
      "metadata": {
        "id": "Blrkx1Rq0zIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora que já conseguimos descrever e explorar nossos dados, podemos exportar o relatório gerado como um arquivo HTML que pode ser utilizado fora do ambiente jupyter. Para isso, basta utilizarmos o seguinte comando:"
      ],
      "metadata": {
        "id": "GyJS28edTgEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "profile.to_file(\"descrevendo_dados.html\")"
      ],
      "metadata": {
        "id": "2mgRjmZK5Q1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após essas etapas, já somos capazes de descrever nosso conjunto de dados, apontar alguns ajustes que devem ser feitos e partir para a etapa de preparação dos dados. A ideia é que uma vez que esses dados estejam em uma estrutura <code>DataFrame</code>, o processo de descrever e explorar o dado seja o mesmo que vimos nesse notebook."
      ],
      "metadata": {
        "id": "owjqEJLQV-sl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referências"
      ],
      "metadata": {
        "id": "8d3M5JD4Xqdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python para Análise de Dados - Wes McKiney. Novatec, São Paulo, 2021.<br/>\n",
        "Projetos de Ciência de Dados com Pyhton - Stephen Klosterman. Novatec, São Paulo, 2020.<br/>\n",
        "[Biblioteca pandas](https://pandas.pydata.org/)<br/>\n",
        "[Biblioteca ydata-profiling](https://docs.profiling.ydata.ai/4.5/)"
      ],
      "metadata": {
        "id": "qtsTQlBaXuL6"
      }
    }
  ]
}